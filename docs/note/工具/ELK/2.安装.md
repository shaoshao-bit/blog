## 安装elasticsearch

apt源里面默认没有es，可以将es的源加入到apt源列表中

首先添加密钥

```bash
wget -qO - <https://artifacts.elastic.co/GPG-KEY-elasticsearch> | sudo apt-key add -
```

将es的源列表添加到/etc/apt/sourse.list.d中

```bash
echo "deb <https://artifacts.elastic.co/packages/6.x/apt> stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list
```

更新apt源

```bash
sudo apt update
```

安装es

```bash
sudo apt install elasticsearch
```

修改es的配置文件

```bash
$ sudo vim /etc/elasticsearch/elasticsearch.yml

#服务名[集群名]
cluster.name: my-application
#节点名
node.name: node-1
#设置此节点具备成为主节点的资格
node.master: true
#为节点添加自定义属性
node.attr.rack: r1
#数据文件存放位置 官方建议自定义
path.data: /var/lib/elasticsearch
#日志文件存放路径 官方建议自定义
path.logs: /var/log/elasticsearch
#启动时锁定内存，默认为true。
#因为当jvm开始swapping时es的效率 会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。 
#同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过ulimit -l unlimited命令来实现。
bootstrap.memory_lock: false
#禁止swapping交换
bootstrap.system_call_filter: false
#为es实例绑定特定的IP地址
network.host: localhost

#es实例设置特定的端口，默认为9200端口
http.port: 9200
#es集群间通信的tcp端口
transport.tcp.port: 8081

#跨域设置
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-credentials: true
```

## 安装logstash

直接用apt安装

```bash
sudo apt install logstash
```

Logstash可以视为一个管道，从一端接收数据，以某种方式处理它，然后将其发送到目的地（在这里是指Elasticsearch）。 Logstash管道有两个必需元素， input和output ，以及一个可选元素filter 。 输入插件使用来自源的数据，过滤器插件处理数据，输出插件将数据写入目标。



在/etc/logstash/logstash.yml写入配置文件路径

```bash
path.config: /etc/logstash/conf.d/logstash_filebeat_exmplate_nginx.yml
```

在上面写到的文件中，添加如下内容

接受5044端口发来的消息，处理后发送到9200端口交由es处理

```bash
input {
  beats {
    port => 5044
  }
}

filter {
           grok {
                   ## grok数据格式整理，可以去官网学习logstash grok格式
                   match => [
                   "message", "%{IPORHOST:http_host} %{IPORHOST:user_ip} - - \\[%{HTTPDATE:timestamp}\\] \\"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion:float})?|%{DATA:rawrequest})\\" %{NUMBER:response:int} (?:%{NUMBER:bytes:int}|-) %{QS:referrer} %{QS:useragent} (?:%{NUMBER:request_time:float}|-) (?:%{NUMBER:upstream_time:float}|-)"
                   ]
           }

     geoip {
                   source => "user_ip"
                   ## 用户IP地址
           }

           date {
                   match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
           }
           useragent {
                   target => "ua"
                   source => "useragent"
           }
   }

output {
    elasticsearch {
      hosts => ["<http://localhost:9200>"]
      index => "nginx_log-%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
      #user => "elastic"
      #password => "changeme"
    }
}
```

## 安装filebeat

```bash
$ sudo apt install filebeat
```

配置filebeat接收nginx日志内容并发送到logstash中

```bash
#配置日志文件路径
filebeat.inputs:

- type: log
  enabled: true
  paths:
    - /var/log/nginx/access.log

......
#配置信息发送到5044端口，交给logstash
output.logstash:
  # The Logstash hosts
  hosts: ["localhost:5044"]
```

## 安装kibana

```bash
$ sudo apt install kibana
```

配置kibana服务端口与es端口

```bash
server.port: 5601

server.host: "10.0.8.11"

elasticsearch.hosts: ["<http://localhost:9200>"]
# 配置语言为中文
i18n.locale: "zh-CN"
```

运行es,其余3个环境同理

```bash
$ sudo service elasticsearch start
```